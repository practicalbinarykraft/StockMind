вижу баг и воспроизводится по скринам: на новом проекте на этапе “AI Analysis → Создать сценарий” прилетает 500: {"message":"AI analysis did not generate scenes"}. Ниже — готовое ТЗ для Реплита (и быстрый хотфикс), чтобы это закрыть.

ТЗ: “AI analysis did not generate scenes” на создании сценария

Контекст и шаги воспроизведения
	1.	Stage 1: выбираю источник = News (RSS).
	2.	Stage 2: выбираю свежую статью (скоры на карточках отображаются).
	3.	Stage 3: на экране форматов жму “Создать сценарий” (например формат Hook & Story).
	4.	Через ~1–3 сек получаю тост с ошибкой 500: {"message":"AI analysis did not generate scenes"}.
 — На уже существующих проектах всё ок; падает на новосозданных.

Ожидаемое поведение
	•	Сценарий создаётся: приходит массив scenes[] (минимум 3, по умолчанию 5), каждая сцена с id, text.
	•	Если LLM вернуло некорректный ответ, система делает до 2 авторемонтных попыток (schema-repair) и только потом показывает понятную ошибку и варианты действий.

Причина вероятнее всего
	•	После недавних рефакторов/модалок сравнения сломан контракт между:
	•	анализом исходника (advanced analysis) и
	•	генерацией сцен по выбранному формату.
Частый кейс: LLM ответ валиден по “review/metrics”, но scenes пустой или поле называется иначе (например sceneList / script / sections), либо контент отрезало по токенам.

Что сделать (бэкенд)
	1.	Жёсткая валидация и авто-ремонт
	•	Ввести Zod-схему GeneratedScript:

{ scenes: [{ id: string; text: string } , ...min 3], format: string, language: 'RU'|'EN' }


	•	После ответа LLM:
a) Валидируем.
b) Если не валидно/scenes.length===0 — repair-процесс:
	•	1-я попытка: system-reprompt с инструкцией: “верни строго JSON по схеме… перепиши сцены кратко, 1–2 предложения на сцену”.
	•	2-я попытка: “Если не знаешь формат — всё равно верни scenes[] длиной 5, сжато”.
	•	Если 2 попытки не дали валидный JSON — возвращаем 422 (а не 500) со структурой:

{ "success": false, "code": "NO_SCENES", "message": "...", "tips": ["Try different format", "Retry"] }


	2.	Унификация полей
	•	На маршруте генерации строго возвращать:

{ success:true, data: { scenes, metrics?, review?, breakdown? } }


	•	Если из модели пришли другие ключи (sceneList, script, sections) — нормализуем в scenes.

	3.	Логирование и диагностика
	•	В server/routes.ts на эндпоинте создания сценария:
	•	логировать projectId, articleId, выбранный format, model, длину исходного текста (tokens), длительность запроса, scenes.length.
	•	При ошибке сохранять сырой LLM-ответ в storage (с привязкой к projectId) для ретроспективы (без PII).
	•	Метрики: счётчик script_gen_empty_scenes_total, гистограмма script_gen_latency_ms.
	4.	Лимиты/чанкинг
	•	Перед вызовом LLM гарантировать укладку в токены:
	•	резать исходник/summary до безопасной длины,
	•	явный max_output_tokens,
	•	краткий промпт.
	•	Если статья очень длинная — использовать “summary → scenes” (двухшаговый) режим.
	5.	Коды ответов
	•	Пустые сцены/невалидный ответ → 422 (Unprocessable Entity), не 500.
	•	Техсбои (Anthropic/ОпенАИ/сеть) → 502/503; включить уже реализованный retry с backoff.

Что сделать (фронтенд)
	1.	Дружелюбная ошибка и recovery
	•	При 422/NO_SCENES показывать модалку:
	•	Заголовок: “Не удалось собрать сцены”.
	•	Кнопки:
	•	“Повторить” (триггерит повтор LLM с repair-промптом),
	•	“Выбрать другой формат” (возврат к списку форматов),
	•	“Сделать черновик из статьи” (см. пункт 2 — fallback).
	•	При 5xx/429: применять ваш общий exponential backoff и информировать “Перепробуем (1/3)…”.
	2.	Локальный fallback (off-LLM)
	•	Если пользователь нажал “Сделать черновик из статьи”, синхронно построить скелет:
	•	взять заголовок + лид анонса,
	•	разрезать summary на 4–6 блоков по смысловым предложениям,
	•	заполнить scenes[] минимально, чтобы человек мог править дальше.
	•	Пометить как isDraft=true и показать баннер “Автодрафт — рекомендуем нажать ‘Пересчитать анализ’”.
	3.	Телеметрия UI
	•	Для этой ошибки отправлять event script_gen_no_scenes с форматами/длиной исходника.

Эндпоинты/файлы (ориентиры)
	•	POST /api/projects/:id/script (или тот, что дергается “Создать сценарий”)
— место валидации и repair.
	•	server/lib/ai-script-generator.ts (или эквивалент) — вынести логику normalise/repair.
	•	client/.../stage-3-ai-analysis.tsx — обработка 422, кнопки Recovery/Retry/Fallback.

Тест-кейсы (acceptance)
	1.	Happy-path: для типовой статьи создаётся 5 сцен, UI переходит к редактору.
	2.	LLM возвращает sceneList → нормализуется в scenes, проходит.
	3.	Пустой ответ → 1-я repair попытка даёт валидный JSON → ок.
	4.	Две repair не помогли → 422 + модалка с кнопками → Fallback создаёт автодрафт (5 сцен).
	5.	Сверхдлинная статья → чанкинг/summary, сцены создаются; время укладывается <30с.
	6.	Сетевая/429 → ретраи, в итоге или success, или информативная ошибка (не “500”).

Быстрый хотфикс (минимум кода)
	•	На сервере, сразу после LLM-ответа:

const out = safeJsonParse(raw);
const scenes = out?.scenes ?? out?.sceneList ?? out?.script ?? out?.sections ?? [];
if (!Array.isArray(scenes) || scenes.length === 0) {
  return apiResponse.unprocessable(res, { success:false, code:'NO_SCENES', message:'Model returned no scenes' });
}


	•	На фронте:
	•	если code==='NO_SCENES' → показать модалку с “Повторить / Выбрать другой формат / Черновик из статьи”.
	•	кнопку “Черновик” — строим 5 сцен локально из summary.

⸻

Если нужно, накину промпт-шаблон для repair-шага и короткий zod для схемы — скажи, добавлю сразу.